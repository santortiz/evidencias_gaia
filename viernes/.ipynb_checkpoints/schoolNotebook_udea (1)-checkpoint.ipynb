{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4773a0a5",
   "metadata": {},
   "source": [
    "# Taller de redes neuronales aplicadas a espectros estelares\n",
    "\n",
    "En este notebook se va a entrenar una red neuronal utilizando la librería sklearn. En concreto, la red neuronal es un objeto de la clase [sklearn.neural_network.MLPRegresor](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html). Posteriormente se utilizará la red neuronal entrenada para inferir parámetros astrofísicos de un conjunto de estrellas cuyos espectros fueron medidos con [RAVE](https://www.rave-survey.org/).\n",
    "\n",
    "Para entrenar dicha red se han generado espectros sintéticos que se han guardado en el fichero *grid_school_v2_8420_8785_003899999999998727.pkl*. Dentro del fichero está guardado, además de los espectros, la temperatura efectiva, el logaritmo de la gravedad y la metalicidad que corresponde a cada espectro; todo ello en formato tabla como un objeto [pandas.DataFrame](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a402a27d",
   "metadata": {},
   "source": [
    "Para comenzar importamos las librerías necesarias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2be4c2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from warnings import simplefilter\n",
    "simplefilter(action=\"ignore\",category=FutureWarning)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c512ba39",
   "metadata": {},
   "source": [
    "Además de las librerías que se han mencionado, se han importado las funciones [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) y [MinMaxScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html) que serán de utilidad para trabajar con los datos de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea000d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Código auxiliar: aunque no es necesario, se definen las longitudes de onda tanto de las simulaciones como de las observaciones\n",
    "wlen = np.arange(842,878.5,0.03899999999998727)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdf8bce",
   "metadata": {},
   "source": [
    "## 1 Preparación de los datos\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c00c8be",
   "metadata": {},
   "source": [
    "### 1.1 Lectura de las simulaciones\n",
    "\n",
    "Primero hay que cargar las simulaciones. Para ello hay que utilizar la función *pandas.read_pickle* que acepta como argumento el nombre del fichero a leer y devuelve un *DataFrame* (nota: para llamar a las funciones de pandas hay que usar pd en lugar de pandas, ya que en la cabecera se ha llamado a la instrucción \n",
    "```\n",
    "import pandas as pd\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4bf6f88",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/grid_school_v2_8420_8785_003899999999998727.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_17822/4110344236.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/grid_school_v2_8420_8785_003899999999998727.pkl'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# rellenar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    194\u001b[0m     \"\"\"\n\u001b[1;32m    195\u001b[0m     \u001b[0mexcs_to_catch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mAttributeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModuleNotFoundError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m     with get_handle(\n\u001b[0m\u001b[1;32m    197\u001b[0m         \u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 711\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    712\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/grid_school_v2_8420_8785_003899999999998727.pkl'"
     ]
    }
   ],
   "source": [
    "grid = pd.read_pickle('data/grid_school_v2_8420_8785_003899999999998727.pkl') # rellenar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4cdc6f",
   "metadata": {},
   "source": [
    "Una vez leído, la variable *grid* tiene estructura de tabla, para saber qué columnas hay almacenadas dentro se puede llamar al atributo *columns*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275e7ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = grid.columns  # rellenar\n",
    "print(cols) #rellenar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af19d60a",
   "metadata": {},
   "source": [
    "Si se quieren ver las primeras filas de la tabla se puede llamar al método *head()* que tiene todo *DataFrame*. El resultado debería ser igual a\n",
    "\n",
    "|  |   teff | logg |  m_h |                                          spectrum|\n",
    "|--|--------|------|------|--------------------------------------------------|\n",
    "|0 | 3000.0 |  0.0 |-3.00 | [0.9997522849383049, 0.9998009367060697, 0.999...|\n",
    "|1 | 3000.0 |  0.0 |-2.75 | [0.9997123698112049, 0.9997728740768044, 0.999...|\n",
    "|2 | 3000.0 |  0.0 |-2.50 | [0.999568427270208, 0.9996652039896338, 0.9997...|\n",
    "|3 | 3000.0 |  0.0 |-2.25 | [0.9993215807872953, 0.9994811204761738, 0.999...|\n",
    "|4 | 3000.0 |  0.0 |-2.00 | [0.9991882596346863, 0.9993762569755674, 0.999...|\n",
    "\n",
    "Por otro lado, si queremos ver una columna en concreto (por ejemplo, la columna j), se puede acceder a ella mediante \n",
    "```\n",
    "nombreDataFrame.iloc[j]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea87e075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rellenar la celda para mostrar las primeras filas almacenadas en grid\n",
    "grid.iloc[10,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208487af",
   "metadata": {},
   "source": [
    "### 1.2 Visualización de las simulaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be7f1ed",
   "metadata": {},
   "source": [
    "En la celda siguiente hay un ejemplo en el que se pinta el espectro almacenado en la primera fila del *DataFrame*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8371a8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "spec = grid[\"spectrum\"].iloc[idx]\n",
    "teff = grid[\"teff\"].iloc[idx]\n",
    "logg = grid[\"logg\"].iloc[idx]\n",
    "mh = grid[\"m_h\"].iloc[idx]\n",
    "label_spec = \"Teff = {} log(g) = {} [m/H] = {}\".format(teff,logg,mh)\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(wlen,spec,label=label_spec)\n",
    "plt.xlabel(r\"$\\lambda /nm$\",size=20)\n",
    "plt.ylabel(r\"Normalized flux\",size=20)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01ef3cc",
   "metadata": {},
   "source": [
    "En la misma figura se pueden representar varios espectros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be724d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx1 = 122 # elige una fila para el primer espectro\n",
    "idx2 = 5 # elige otra fila para el segundo espectro\n",
    "\n",
    "spec1 = grid[\"spectrum\"].iloc[idx1]\n",
    "teff1 = grid[\"teff\"].iloc[idx1]\n",
    "logg1 = grid[\"logg\"].iloc[idx1]\n",
    "mh1 = grid[\"m_h\"].iloc[idx1]\n",
    "label_spec1 = \"Teff = {} log(g) = {} [m/H] = {}\".format(teff1,logg1,mh1)\n",
    "\n",
    "# rellenar para definir las variables del segundo espectro\n",
    "\n",
    "spec2 = grid[\"spectrum\"].iloc[idx2]\n",
    "teff2 = grid[\"teff\"].iloc[idx2]\n",
    "logg2 = grid[\"logg\"].iloc[idx2]\n",
    "mh2 = grid[\"m_h\"].iloc[idx2]\n",
    "label_spec2 = \"Teff = {} log(g) = {} [m/H] = {}\".format(teff2,logg2,mh2)\n",
    "    \n",
    "\n",
    "# rellenar para dibujar los dos espectros\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "\n",
    "plt.plot(wlen,spec1,label=label_spec1)\n",
    "plt.plot(wlen,spec2,label=label_spec2)\n",
    "\n",
    "plt.xlabel(r\"$\\lambda /nm$\",size=20)\n",
    "plt.ylabel(r\"Normalized flux\",size=20)\n",
    "plt.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b2f60c",
   "metadata": {},
   "source": [
    "Además, se pueden seleccionar las columnas guardadas en el *DataFrame* de *pandas* simplemente poniendo entre corchetes los nombres de las variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14069727",
   "metadata": {},
   "outputs": [],
   "source": [
    "teffs = grid[\"teff\"] # rellenar para escoger la columna de las temperaturas\n",
    "loggs = grid[\"logg\"] # columna de las gravedades\n",
    "mhs = grid[\"m_h\"] # columna de las metalicidades\n",
    "\n",
    "plt.figure(figsize=(21,8))\n",
    "plt.subplot(131)\n",
    "plt.hist(teffs,bins=100)\n",
    "plt.xlabel(r\"$T_{eff}$\")\n",
    "plt.subplot(132)\n",
    "plt.hist(loggs,bins=100)\n",
    "plt.xlabel(r\"$log(g)$\")\n",
    "plt.subplot(133)\n",
    "plt.hist(mhs,bins=100)\n",
    "plt.xlabel(r\"$[M/H]$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76aa3abb",
   "metadata": {},
   "source": [
    "### 1.3 Preparación de las simulaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b950c5b",
   "metadata": {},
   "source": [
    "Una vez observados y entendidos los datos simulados con los que se puede trabajar es cuando se van a preparar para poder usarlos en el entrenamiento de la red neuronal.\n",
    "\n",
    "La red es lo que se llama un perceptrón totalmente conectado y queremos entrenarlo para que lea un espectro y como resultado nos diga qué parámetros astrofísicos (temperatura efectiva, logaritmo de la gravedad y metalicidad) tiene la estrella que produce dicho espectro. Por tanto, los valores de entrada de la red serán los valores del espectro para las distintas longitudes de onda y los valores de salida serán tres: temperatura, gravedad y metalicidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9684e905",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = grid[[\"teff\",\"logg\",\"m_h\"]].values\n",
    "x = grid[\"spectrum\"].values # rellenar \n",
    "x = np.array([xx.astype(float) for xx in x]) # este paso es necesario debido a la implementación de sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff844c3",
   "metadata": {},
   "source": [
    "A la hora de ayudar al programa de minimización a encontrar el mínimo es útil escalar las variables de manera que el rango entre ellas sea aproximadamente igual. Para esto vamos a utilizar el objeto [MinMaxScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html) de la librería *sklearn*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193d2561",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "ys = scaler.fit_transform(y) # rellenar con la variable que se quiere escalar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfb469b",
   "metadata": {},
   "source": [
    "Una vez preprocesados los datos sintéticos hay que decidir qué datos se utilizarán para entrenar y cuáles de ellos (el resto) para comprobar. Ésto se logra fácilmente con la función *train_test_split* que recibe como primer y segundo argumentos dos *arrays* que va a separar en dos conjuntos cada uno de ellos, el conjunto de entrenamiento (*train*) y el conjunto de comprobación (*test*). Además, admite otro argumento mediante la [clave](https://docs.python.org/3/glossary.html#term-argument) *test_size* cuyo valor va de 0 a 1 y que define qué porcentaje de elementos de los arrays se utilizarán para entrenar y qué porcentaje se utilizarán para comprobar. Los valores típicos suelen ser 0.1, 0.15 y 0.2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4097dfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain,xtest,ytrain,ytest = train_test_split(x,ys,test_size=.2) # rellenar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75a1257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rellenar la celda para mostrar tres gráficas con las variables de referencia que se usarán para entrenar\n",
    "# nota: en una celda anterior se mostraron gráficas con los parámetros astrofísicos de entrada, ésta puede ser de ayuda\n",
    "\n",
    "teffs = ytrain[:,0] # rellenar para escoger la columna de las temperaturas\n",
    "loggs = ytrain[:,1] # columna de las gravedades\n",
    "mhs = ytrain[:,2] # columna de las metalicidades\n",
    "\n",
    "plt.figure(figsize=(21,8))\n",
    "plt.subplot(131)\n",
    "plt.hist(teffs,bins=100)\n",
    "plt.xlabel(r\"$T_{eff}$\")\n",
    "plt.subplot(132)\n",
    "plt.hist(loggs,bins=100)\n",
    "plt.xlabel(r\"$log(g)$\")\n",
    "plt.subplot(133)\n",
    "plt.hist(mhs,bins=100)\n",
    "plt.xlabel(r\"$[M/H]$\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff6b770",
   "metadata": {},
   "source": [
    "A la vista de los gráficos anteriores, ¿se distribuyen los datos de entrenamiento como queremos?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06051f8",
   "metadata": {},
   "source": [
    "## 2 Construcción de la red"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7931d677",
   "metadata": {},
   "source": [
    "La definición de la red se hace a través de parámetros e hiperparámetros. Algunos de ellos hacen referencia a la arquitectura de la propia red mientras que otros definen la estrategia a seguir para la optimización de los parámetros de la red."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb2dde7",
   "metadata": {},
   "source": [
    "### 2.1 Parámetros de la red\n",
    "\n",
    "Los parámetros que definen la red son las funciones de activación así como el número de capas \n",
    "ocultas y de neuronas por capa.\n",
    "\n",
    "Cuando se trabaja con *MLPRegressor* esto se hace con los argumentos *activation* y *hidden_layer_sizes*.\n",
    "\n",
    "- activation: función de activación de las neuronas. Admite un sólo valor entre \"logistic\", \"linear\", \"tanh\" y \"relu\" \n",
    "- hidden_layer_sizes: define el número de capas ocultas y el número de neuronas que hay en cada capa. El argumento es una tupla cuya longitud denota el número de capas ocultas y cuyos valores marcan el número de neuronas en las capas. Así, por ejemplo, una neurona con 2 capas ocultas y tres neuronas en cada capa vendría definida por\n",
    "``` \n",
    "hidden_layer_sizes=(3,3)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e88fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = 'logistic' # elegir una función de activación\n",
    "hidden_layer_sizes = (int(len(wlen)/4)) # elegir el número de capas ocultas así como las neuronas en cada capa\n",
    "alpha = 1e-3 # término de regularización"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192ee9d4",
   "metadata": {},
   "source": [
    "### 2.2 Parámetros para el optimizador\n",
    "\n",
    "Una vez definida la red quedan por definir tanto el optimizador como los parámetros que se \n",
    "pasarán a éste.\n",
    "\n",
    "El primero de ellos es el optimizador que se va a utilizar (\"lbfgs\", \"sgd\" o \"adam\"), mientras que los otros dos hacen referencia al desplazamiento de la solución que se obtiene tras cada iteración. Estos argumentos vienen especificados por *learning_rate_init* y por *learning_rate* que hacen referencia al valor del módulo del desplazamiento y los cambios que se le pueden aplicar respectivamente. Así, un valor de *learning_rate* igual a *\"constant\"* mantendrá el módulo del paso constante, mientras que *\"adaptive\"* lo irá variando en función de la solución actual en cada iteración."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eceb992",
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = 'adam' # elige un optimizador\n",
    "learning_rate_init = 1e-3 # elige un paso\n",
    "learning_rate = 'adaptive' # elegir la estrategia a seguir con el paso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81305c12",
   "metadata": {},
   "source": [
    "El siguiente conjunto de parámetros hace referencia a las iteraciones del optimizador en el proceso de minimización. Éstos son:\n",
    "- número máximo de iteraciones del optimizador: el optimizador realizará iteraciones hasta que converja o se alcance *max_iter*.\n",
    "- *tol*: define lo que se entiende por convergencia\n",
    "- *n_iter_no_change*: número máximo de iteraciones para que la función de pérdida disminuya\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba458e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iter = 400 # número máximo de iteraciones\n",
    "tol = 1e-4 # tolerancia\n",
    "n_iter_no_change = 10 # númer máximo de épocas permitidas para que la función de pérdida disminuya"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf25701",
   "metadata": {},
   "source": [
    "Finalmente, queda por definir el conjunto de validación. Este conjunto se puede definir a mano y no especificar el siguiente conjunto de parámetros, sin embargo, el objeto *MLPRegressor* nos permite hacer el proceso de creación del conjunto de validación simplemente especificando un parámetro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10652ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_fraction = 0.2 # fracción de elementos de entrada que se usarán para formar el conjunto de validación\n",
    "early_stopping=True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e367ab",
   "metadata": {},
   "source": [
    "### 2.3 Definición de la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a8a8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = MLPRegressor(\n",
    "    activation=activation,\n",
    "    hidden_layer_sizes=hidden_layer_sizes,\n",
    "    solver=solver,\n",
    "    learning_rate_init=learning_rate_init,\n",
    "    learning_rate=learning_rate,\n",
    "    max_iter=max_iter,\n",
    "    tol=tol,\n",
    "    n_iter_no_change=n_iter_no_change,\n",
    "    validation_fraction=validation_fraction,\n",
    "    verbose=True,\n",
    "    early_stopping=early_stopping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2c5170",
   "metadata": {},
   "source": [
    "## 3 Entrenamiento\n",
    "\n",
    "Una vez definidos los conjuntos de entrenamiento y los parámetros de la red, el entrenamiento se hace a través del método *fit()* que recibe como primer argumento el conjunto de datos de entrada para el entrenamiento y como segundo el conjunto de datos de salida con los que debe contrastar la propia salida de la red. El proceso de ajuste de la red neuronal consiste, precisamente, en comparar las salidas de la red con el conjunto de entrada y minimizar el error cuadrático medio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adf6aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rellenar esta celda con la llamada a la función fit para entrenar la red\n",
    "\n",
    "net.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a9d759",
   "metadata": {},
   "source": [
    "## 4 Mostrar y guardar los resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb0339c",
   "metadata": {},
   "source": [
    "Cuando el entrenamiento ha terminado los parámetros (b,w) - bias, weight - de la red se han ajustado de manera que ajustan la salida de la red al conjunto de datos *ytrain*. Estos valores se pueden llamar mediante los atributos *intercepts_* y *coefs_*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f36f9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar por pantalla los parámetros b y w de la red nuronal\n",
    "print(net.intercepts_, net.coefs_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89804477",
   "metadata": {},
   "source": [
    "Para guardar la red neuronal ya entrenada vamos a utilizar la librería *pickle* de Python. Los comandos a ejecutar son:\n",
    "```\n",
    "output_file_name = \"nombre de salida del fichero a guardar\"\n",
    "pickle.dump(nombre_de_la_red,open(output_file_name,\"wb\"))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76034c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rellenar la celda con el código necesario para guardar la red\n",
    "output_file_name= 'out_net.pkl'\n",
    "pickle.dump(net,open(output_file_name,\"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363d88b1",
   "metadata": {},
   "source": [
    "El valor de pérdida (el error cuadrático entre la salida de la red y los valores ytrain) de la red se puede obtener llamando al atributo *loss_* mientras que los valores para cada iteración se obtienen con el atributo *loss_curve_*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b506475e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Muestra por pantalla el valor actual de pérdida y dibuja en una gráfica la curva de pérdida\n",
    "plt.plot(range(len(net.loss_curve_)), net.loss_curve_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a78b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mustra por pantalla el score para el conjunto de entrenamiento. \n",
    "#¿Cómo compara con el valor mostrado en el entrenamiento con el del conjunto de validación?\n",
    "\n",
    "net.score(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2803b696",
   "metadata": {},
   "source": [
    "## 5 Estudio de las incertidumbres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1960b6a1",
   "metadata": {},
   "source": [
    "Una vez entrenada la red se utiliza el conjunto *test* para comprobar los resultados y caracterizar las incertidumbres. Dado un conjunto de espectros de entrada, la red asignará a cada espectro un valor de salida que corresponde con una temperatura, una gravedad y una metalicidad. Para obtener estos valores se utiliza el método *predict()* de la red neuronal.\n",
    "\n",
    "Hay que recordar que la red fue entrenada con los objetivos (valores de salida) escalados y hay que desescalarlos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7926921b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener los parámetros estelares que la red entrenada asocia a los espectros del conjunto test\n",
    "# Recordar que los valores de los parámetros con los que se entrenó la red han sido escalados.\n",
    "\n",
    "test_predictions = scaler.inverse_transform(net.predict(xtest))# rellenar los huecos con los valores para obtener las predicciones de la red asociadas a los espectros del conjunto test\n",
    "test_values = scaler.inverse_transform(ytest) # rellenar para obtener los valores de los parámetros reales del conjunto test\n",
    "\n",
    "print(test_predictions) # rellenar para mostrar los valores de las predicciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a28d776",
   "metadata": {},
   "source": [
    "El error medio o *bias* para cada variable viene dado por el valor medio de la distribución *valores_de_la_red* - *valores_reales*. Para obtener estas distribuciones tenemos que acceder a los elementos de *test_predictions* y *test_values* que corresponden a cada parámetro astrofísico. Éstos están guardados en el orden en que los definimos (temperatura, gravedad, metalicidad).\n",
    "\n",
    "Dado un *array* de *arrays*, si se quiere acceder al primer elemento de cada uno de los *arrays* se puede utilizar la siguiente nomenclatura:\n",
    "```\n",
    "primer_valor_cada_array = array_de_array[:,0]\n",
    "```\n",
    "Cambiando el índice se puede obtener todos los segundos, los terceros, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f94662e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construir las distribuciones de predicciones menos valores reales\n",
    "delta_teff = test_predictions[:,0] - test_values[:,0] # rellenar los huecos\n",
    "delta_logg = test_predictions[:,1] - test_values[:,1] # rellenar los huecos # rellenar\n",
    "delta_mh = test_predictions[:,2] - test_values[:,2] # rellenar los huecos # rellenar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f26e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ilustrar en un gráfico las distribuciones de diferencias (deltas). Para ello pintar un histograma usando plt.hist(). \n",
    "\n",
    "plt.figure(figsize=(21,8))\n",
    "plt.subplot(131)\n",
    "plt.hist(delta_teff,bins=100)\n",
    "plt.xlabel(r\"$T_{eff}$\")\n",
    "plt.subplot(132)\n",
    "plt.hist(delta_logg,bins=100)\n",
    "plt.xlabel(r\"$log(g)$\")\n",
    "plt.subplot(133)\n",
    "plt.hist(delta_mh,bins=100)\n",
    "plt.xlabel(r\"$[M/H]$\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23ff6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# en esta celda vamos a obtener los biases y las uncertidumbres.\n",
    "# para obtenerlas hay que utilizar los métodos mean() y std() \n",
    "bias_teff = delta_teff.mean()\n",
    "bias_logg = delta_logg.mean()\n",
    "bias_mh = delta_mh.mean()\n",
    "uncert_teff = delta_teff.std()\n",
    "uncert_logg = delta_logg.std()\n",
    "uncert_mh = delta_mh.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde8dcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mostrar los resultados de bias y uncert para cada variable\n",
    "print(\"Teff: bias = {} and unc = {}\".format(bias_teff,uncert_teff))\n",
    "print(\"logg: bias = {} and unc = {}\".format(bias_logg,uncert_logg))\n",
    "print(\"mh: bias = {} and unc = {}\".format(bias_mh,uncert_mh))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ff17c9",
   "metadata": {},
   "source": [
    "## 6 Nota final para el entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976a8860",
   "metadata": {},
   "source": [
    "Normalmente hay que realizar un estudio detallado para encontrar la configuración óptima de la red a través de los posibles valores de parámetros e hiperparámetros. La configuración óptima dependerá del tipo de problema que se quiere resolver, los datos de entrenamiento...; por ello es bueno cambiar la arquitectura y los valores de los parámetros y entrenar con los mismos datos.\n",
    "\n",
    "Utiliza las celdas de debajo (tantas como necesites) para construir nuevas redes y comparar los resultados que dan cada una de ellas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac4fa03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db10ec7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e466ed5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b149d9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc97a28e",
   "metadata": {},
   "source": [
    "## 7 Aplicación a espectros reales (medidos por RAVE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767f1d6a",
   "metadata": {},
   "source": [
    "Ahora se va a aplicar la red neuronal entrenada a datos reales. \n",
    "Los ficheros *input_spectra_X.pkl* contienen espectros medidos por el experimento [RAVE](https://www.rave-survey.org/) y, a partir de ellos, la red neuronal va a asignar a cada espectro una temperatura efectiva, un logaritmo de la gravedad y una metalicidad. Posteriormente, se mostrará en un gráfico las gravedades frente a las temperaturas. Así, el esquema de este análisis es:\n",
    "- Lectura de datos: entender las diferencias entre los datos y las simulaciones\n",
    "- Determinación de los parámetros astrofísicos\n",
    "- Dibujar el diagrama de logg vs Teff (¿es, en tu caso, necesaria una corrección?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c49926f",
   "metadata": {},
   "source": [
    "### 7.1 Lectura de datos\n",
    "\n",
    "Puesto que los ficheros de datos están separados, por comodidad vamos a crear un *DataFrame* vacío y, mediante un bucle for, vamos a ir almacenando las tablas de cada fichero en el mismo *DataFrame*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace459ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rellenar el hueco para leer los datos y almacenarlos en data\n",
    "data = pd.DataFrame()\n",
    "for i in range(20):\n",
    "    data = pd.concat((data,pd.read_pickle(\"data/input_spectra_{}.pkl\".format(i))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bd2d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pintar algunos espectros\n",
    "idx = 21 \n",
    "plt.figure(figsize=(13,8))\n",
    "plt.plot(wlen,data[\"spectrum\"].iloc[idx])\n",
    "plt.xlabel(r\"$\\lambda /nm$\")\n",
    "plt.ylabel(r\"$Normalized flux$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c55a48",
   "metadata": {},
   "source": [
    "### 7.2 Inferencia: determinación de parámetros astrofísicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29783ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_specs = data[\"spectrum\"].values.tolist() # obtener los valores de los espectros. Nota: se convierte a una lista porque MLPRegressor.predict recibe como argumento una lista\n",
    "data_preds = scaler.inverse_transform(net.predict(data_specs)) # aplicar la red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46dcccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utiliza esta celda (y tantas como necesites) para explorar los resultados\n",
    "\n",
    "data_preds.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c7b7d4",
   "metadata": {},
   "source": [
    "### 7.3 Diagrama de inferencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1766636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rellenar para dibujar el diagrama.\n",
    "# Nota: el diagrama que se quiere dibujar debe tener los ejes invertidos. Si se quiere dibujar el eje X invertido hay que llamar a la instrucción plt.gca().invert_xaxis()\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.gca().invert_xaxis()\n",
    "plt.gca().invert_yaxis()\n",
    "plt.hexbin(data_preds[:,0], data_preds[:,1], mincnt=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a3540c-77c5-4202-96bb-9f1dcf5c5304",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
